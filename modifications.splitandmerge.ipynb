{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9565f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cassa\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "usage: ipykernel_launcher.py [-h] --input-file INPUT_FILE [--output-folder OUTPUT_FOLDER]\n",
      "                             [--merge-threshold MERGE_THRESHOLD] [--split-threshold SPLIT_THRESHOLD]\n",
      "                             [--min-size MIN_SIZE] [--homogeneity-strategy {minMax,variance}]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --input-file\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cassa\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3377: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "## #     3D split and Merge segmentation algorithm  #\n",
    "#         Author = JY Ramel - June 2023          #\n",
    "##################################################\n",
    "# see the initial jupyter notebook if necessary 3Dsplitmerge.ipynb\n",
    "\n",
    "# modifications applied but not working \n",
    "\n",
    "# Import the modules\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import networkx as nx\n",
    "from scipy.ndimage import median_filter,gaussian_filter\n",
    "from itertools import combinations\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "#from matplotlib import pyplot as plt\n",
    "#from scipy import ndimage as ndi\n",
    "#import math\n",
    "#from skimage import exposure\n",
    "\n",
    "\n",
    "# Functions for pre-processing of the 3D image\n",
    "def mg_filter_3d_nifti(input_data, sigma=0, kernel_size = (3,3,3)):\n",
    "    \"\"\"\n",
    "    3D median or gaussian filtering : gaussian if sigma != 0 else median with kernel_size\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data: the 3D volume\n",
    "    (3,) ndarray\n",
    "    kernel_size: the 3D size of the kernel\n",
    "    [3,3,3)]\n",
    "    sigma: for the gaussian filtering > 0\n",
    "    1.5 float\n",
    "    Returns\n",
    "    -------\n",
    "    the filtered volume        \n",
    "    \"\"\"    \n",
    "    if sigma==0:\n",
    "        # Apply 3D median filtering using scipy's median_filter\n",
    "        filtered_data = median_filter(input_data, size=kernel_size)\n",
    "        print(\"- Median filtering done.\")\n",
    "    else:\n",
    "        # Apply true 3D smoothing using scipy's gaussian_filter\n",
    "        filtered_data = gaussian_filter(input_data, sigma=sigma)\n",
    "        print(\"- Gaussian filtering done.\")\n",
    "    \n",
    "    return filtered_data.astype(np.uint16)\n",
    "\n",
    "\n",
    "\n",
    "# Functions for gray level normalization of the 3D image\n",
    "def normalize_data(data):\n",
    "    \"\"\"\n",
    "    Normalize gray level to 255 stored in uint16 by using min and max values of the volume\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data: the 3D volume\n",
    "    Returns\n",
    "    -------\n",
    "    the normalized volume        \n",
    "    \"\"\" \n",
    "    data_min = np.min(data)\n",
    "    data_max = np.max(data)\n",
    "    #normalized_data = (255*(data - data_min) / (data_max - data_min)).astype(np.uint16)\n",
    "    normalized_data = (data - data_min) / (data_max - data_min)\n",
    "    # Convert the normalized data to an array of integers in the range [0, 255]\n",
    "    normalized_array = (normalized_data * 255).astype(np.uint16)\n",
    "\n",
    "    print(\"- Gray level normalisation to 255 done.\")\n",
    "    return normalized_array\n",
    "\n",
    "\n",
    "def augment_contrast(imgdata):\n",
    "    \"\"\"\n",
    "    Augment contrast of the 3D volume by applying histogram equalization on each slice\n",
    "    Parameters\n",
    "    ----------\n",
    "    imgdata: the 3D volume\n",
    "    Returns\n",
    "    -------\n",
    "    the augmented volume\n",
    "    \"\"\"\n",
    "    augmented_data = np.empty_like(imgdata)\n",
    "    for i in range(imgdata.shape[-1]):\n",
    "        augmented_data[..., i] = apply_histogram_equalization(imgdata[..., i])\n",
    "    \n",
    "    return augmented_data\n",
    "\n",
    "def apply_histogram_equalization(image_slice):\n",
    "    \"\"\"\n",
    "    Apply histogram equalization on a 2D image slice\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_slice: the 2D image slice\n",
    "    Returns\n",
    "    -------\n",
    "    the augmented image slice\n",
    "    \"\"\"\n",
    "    image_slice = cv2.equalizeHist(image_slice.astype(np.uint8))\n",
    "    return image_slice\n",
    "\n",
    "\n",
    "# The post-processing of a 3D segmentation to remove small regions\n",
    "def remove_merge_again(labels, data_3Dimg, msize):\n",
    "    \"\"\"    \n",
    "    Remove or merge small regions resulting from a segmentation (split and merge) and normalize label values to int16\n",
    "    (number of ROI should be less than 32000)\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels: list of region labels\n",
    "    data_3Dimg: the 3D volume containing the labels of the region for each voxel (0=background)\n",
    "    msize: minimum size of a region\n",
    "8   Returns\n",
    "    -------\n",
    "    final list of labels of regions\n",
    "    the segmented 3D volume (with region_label on each voxel)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Post-processing to remove small regions (\",msize,\") and normalize label values to be saved in int16...\")        \n",
    "    data_img_copy = np.zeros_like(data_3Dimg, dtype=np.int16)\n",
    "    newlabelvalue = 1\n",
    "    fusion = 0\n",
    "\n",
    "    for lab in labels :\n",
    "        binary_mask = (data_3Dimg == lab)        \n",
    "        segment_size = np.sum(binary_mask)\n",
    "        if segment_size < msize or lab == 0:            \n",
    "            data_img_copy[binary_mask == 1] = 0\n",
    "            fusion+=1    # fusion with background - one  of the fusion is not a real one when lab == 0\n",
    "        else:\n",
    "            data_img_copy[binary_mask == 1] = newlabelvalue\n",
    "            newlabelvalue = newlabelvalue+1\n",
    "            \n",
    "    print(\"Deletion / Fusion = \", fusion - 1)     \n",
    "    new_labels = np.unique(data_img_copy)    \n",
    "\n",
    "    return new_labels, data_img_copy\n",
    "\n",
    "\n",
    "# 3D Crop function into a 3D volume / image \n",
    "def crop_3D(data, start_coord, end_coord):\n",
    "    \"\"\"\n",
    "    Crop a volume inside the 3D data of a 3D image\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: the 3D volume\n",
    "    (3,) ndarray\n",
    "    The x,y,z minimum coordinates that delimite the crop\n",
    "    xyzmax: (3,) ndarray\n",
    "    The x,y,z maxymum coordinates that delimite the  crop\n",
    "    Returns\n",
    "    -------\n",
    "    the cropped volume        \n",
    "    \"\"\"\n",
    "    # Convert coordinates to integers\n",
    "    start_coord = np.round(start_coord).astype(int)\n",
    "    end_coord = np.round(end_coord).astype(int)\n",
    "\n",
    "    # Crop the subcube\n",
    "    cropped_data = data[start_coord[0]:end_coord[0], start_coord[1]:end_coord[1], start_coord[2]:end_coord[2]]\n",
    "\n",
    "    return cropped_data\n",
    "\n",
    "\n",
    "\n",
    "# Create Object Cube as a dictionary \n",
    "def create_cube(\n",
    "        xyzmin,\n",
    "        xyzmax,\n",
    "        graymin,\n",
    "        graymax,\n",
    "        graymean,\n",
    "        variance,\n",
    "        leaf=False,\n",
    "        level=0):\n",
    "    \"\"\"\n",
    "    Create a cube object with appropriate descriptors coming from the 3D image\n",
    "    Parameters\n",
    "    ----------\n",
    "    xyzmin: the x,y,z minimum coordinates of the cube\n",
    "    xyzmax: the x,y,z maximum coordinates of the cube\n",
    "    graymin: the minimum gray level inside the cube\n",
    "    graymax: the maximum gray level inside the cube\n",
    "    graymean: the mean gray level inside the cube\n",
    "    variance: the variance of gray level inside the cube\n",
    "    leaf: boolean to say if the cube is a leaf or not\n",
    "    level: the level of the cube in the octree\n",
    "    Returns\n",
    "    -------\n",
    "    a cube object with attributes : ndarray\n",
    "    \"\"\"\n",
    "    volume = (xyzmax[0]-xyzmin[0])*(xyzmax[1]-xyzmin[1])*(xyzmax[2]-xyzmin[2])\n",
    "    cube = {\n",
    "        'xyzmin':np.array(xyzmin, dtype = int), \n",
    "        'xyzmax':np.array(xyzmax, dtype = int), \n",
    "        'leaf':leaf,\n",
    "        'level':level,\n",
    "        'graymin':graymin,\n",
    "        'graymax':graymax,\n",
    "        'graymean':graymean,\n",
    "        'variance':variance,\n",
    "        'volume':volume,\n",
    "        'region_label':0\n",
    "        }    \n",
    "    return cube\n",
    "\n",
    "\n",
    "# A function to sort the edges of a graph accoring an attribute\n",
    "def sort_edges_by_attribute(graph, attribute):\n",
    "    sorted_edges = sorted(graph.edges(data=True), key=lambda x: x[2].get(attribute, float('inf')))\n",
    "    return sorted_edges\n",
    "\n",
    "\n",
    "def find_cube_edges(su_x, su_y, su_z):\n",
    "    \"\"\"\n",
    "    Find the points of the edges of a cube\n",
    "    Parameters\n",
    "    ----------\n",
    "    su_x: the x minimum and maximum coordinates of the cube\n",
    "    su_y: the y minimum and maximum coordinates of the cube\n",
    "    su_z: the z minimum and maximum coordinates of the cube\n",
    "    Returns\n",
    "    -------\n",
    "    a list of the points of the edges of the cube\n",
    "    \"\"\"\n",
    "    arrete_points = []\n",
    "    [arrete_points.append((x, su_y[0], su_z[0])) for x in range(su_x[0], su_x[1]+1)]\n",
    "    [arrete_points.append((x, su_y[0], su_z[1])) for x in range(su_x[0], su_x[1]+1)]\n",
    "    [arrete_points.append((x, su_y[1], su_z[0])) for x in range(su_x[0], su_x[1]+1)]\n",
    "    [arrete_points.append((x, su_y[1], su_z[1])) for x in range(su_x[0], su_x[1]+1)]\n",
    "    [arrete_points.append((su_x[0], y, su_z[0])) for y in range(su_y[0], su_y[1]+1)]\n",
    "    [arrete_points.append((su_x[0], y, su_z[1])) for y in range(su_y[0], su_y[1]+1)]\n",
    "    [arrete_points.append((su_x[1], y, su_z[0])) for y in range(su_y[0], su_y[1]+1)]\n",
    "    [arrete_points.append((su_x[1], y, su_z[1])) for y in range(su_y[0], su_y[1]+1)]\n",
    "    [arrete_points.append((su_x[0], su_y[0], z)) for z in range(su_z[0], su_z[1]+1)]\n",
    "    [arrete_points.append((su_x[0], su_y[1], z)) for z in range(su_z[0], su_z[1]+1)]\n",
    "    [arrete_points.append((su_x[1], su_y[0], z)) for z in range(su_z[0], su_z[1]+1)]\n",
    "    [arrete_points.append((su_x[1], su_y[1], z)) for z in range(su_z[0], su_z[1]+1)]\n",
    "    return arrete_points\n",
    "\n",
    "\n",
    "# A function to find the adjacencies of all cubes in the graph\n",
    "def find_cube_adjacencies(g):\n",
    "    \"\"\"\n",
    "    Find the adjacencies of all cubes in the graph\n",
    "    Parameters\n",
    "    ----------\n",
    "    g: the graph corresponding to the splitted 3D volume\n",
    "    Returns\n",
    "    -------\n",
    "    the number of edges in the graph\n",
    "    \"\"\"\n",
    "    print(\"Creating matrix\")\n",
    "    N = g.number_of_nodes() + 1\n",
    "    nbedges = 0\n",
    "    matrice_3D = {}\n",
    "\n",
    "    for s in range(1, N):\n",
    "        su_x = g.nodes[s]['xyzmin'][0], g.nodes[s]['xyzmax'][0]\n",
    "        su_y = g.nodes[s]['xyzmin'][1], g.nodes[s]['xyzmax'][1]\n",
    "        su_z = g.nodes[s]['xyzmin'][2], g.nodes[s]['xyzmax'][2]\n",
    "\n",
    "        arrete_points = find_cube_edges(su_x, su_y, su_z)\n",
    "        \n",
    "        for (x, y, z) in arrete_points:\n",
    "            if (x, y, z) not in matrice_3D:\n",
    "                matrice_3D[(x, y, z)] = []\n",
    "            if s not in matrice_3D[(x, y, z)]:\n",
    "                matrice_3D[(x, y, z)].append(s)\n",
    "\n",
    "    for _, adj_nodes in matrice_3D.items():\n",
    "        couples = combinations(adj_nodes, 2)\n",
    "        for couple in couples:\n",
    "            grmin = min(g.nodes[couple[0]]['graymin'], g.nodes[couple[1]]['graymin'])\n",
    "            grmax = max(g.nodes[couple[0]]['graymax'], g.nodes[couple[1]]['graymax'])\n",
    "            toplevel = min(g.nodes[couple[0]]['level'], g.nodes[couple[1]]['level'])\n",
    "            attributs = {'level': toplevel, 'graymin': grmin, 'graymax': grmax}\n",
    "            if not g.has_edge(couple[0], couple[1]):\n",
    "                g.add_edge(couple[0], couple[1], **attributs)\n",
    "                nbedges += 1\n",
    "\n",
    "    return nbedges\n",
    "\n",
    "\n",
    "\n",
    "# split a cube into 8 sub-parts to expand the octree\n",
    "def split(cube, minsize=4):\n",
    "    \"\"\"\n",
    "    Splits the cube into 8 sub-nodes\n",
    "    Parameters\n",
    "    ----------\n",
    "    cube: dictionary\n",
    "    \n",
    "    minsize:  int\n",
    "    min size of the chiild cubes (less than 4 can raise pb when cropping - see also cutting boundaries below)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    octree : (8,2,3) ndarray\n",
    "        return an array of 8 sub-cubes\n",
    "        The x,y,z minimum and maximum coordiantes of the sub-cubes are grouped along the second dimension\n",
    "    \"\"\"\n",
    "\n",
    "    xyzmin = cube[\"xyzmin\"]\n",
    "    xyzmax = cube[\"xyzmax\"]\n",
    "    \n",
    "    if(xyzmax[0]-xyzmin[0] < minsize or xyzmax[1]-xyzmin[1] < minsize or xyzmax[2]-xyzmin[2] < minsize) :\n",
    "        octree=  np.zeros([8,2,3], dtype = float )                \n",
    "    else:\n",
    "        xyzmed = (xyzmax + xyzmin) / 2\n",
    "    \n",
    "        octree = np.array([\n",
    "        [[xyzmin[0], xyzmin[1], xyzmin[2]], [xyzmed[0], xyzmed[1], xyzmed[2]]],\n",
    "        [[xyzmin[0], xyzmed[1], xyzmin[2]], [xyzmed[0], xyzmax[1], xyzmed[2]]],\n",
    "        [[xyzmed[0], xyzmed[1], xyzmin[2]], [xyzmax[0], xyzmax[1], xyzmed[2]]],\n",
    "        [[xyzmed[0], xyzmin[1], xyzmin[2]], [xyzmax[0], xyzmed[1], xyzmed[2]]],\n",
    "        [[xyzmin[0], xyzmin[1], xyzmed[2]], [xyzmed[0], xyzmed[1], xyzmax[2]]],\n",
    "        [[xyzmin[0], xyzmed[1], xyzmed[2]], [xyzmed[0], xyzmax[1], xyzmax[2]]],\n",
    "        [[xyzmed[0], xyzmed[1], xyzmed[2]], [xyzmax[0], xyzmax[1], xyzmax[2]]],\n",
    "        [[xyzmed[0], xyzmin[1], xyzmed[2]], [xyzmax[0], xyzmed[1], xyzmax[2]]], \n",
    "        ]) \n",
    "      \n",
    "    return octree\n",
    "    \n",
    "\n",
    "\n",
    "# convert the octree (8 childs of a cube) into leafs or cubes according to the 3D image info\n",
    "def octree2cube(cube, octree, imgdata, threshold, strategy):\n",
    "    \"\"\"\n",
    "    Converts simple cube with xoord into cube objects with appropriate descriptors coming from the 3D image\n",
    "    Parameters\n",
    "    ----------\n",
    "    cube: the parent cube\n",
    "    octree:  the 8 children cubest\n",
    "    threshold : similarity value for voxel intensity inside a cube to decide to split it again (leaf == false) or not (leaf == true)\n",
    "    Returns\n",
    "    -------\n",
    "    a list of 8 cubes with attributes : ndarray        \n",
    "    \"\"\"\n",
    "\n",
    "    clist = []\n",
    "    newlevel = cube['level'] + 1\n",
    "    \n",
    "    for o in octree :\n",
    "        xyzmin = o[0].astype(int)\n",
    "        xyzmax = o[1].astype(int)\n",
    "        cropped_data = crop_3D(imgdata, xyzmin,xyzmax)\n",
    "        gmin = np.min(cropped_data)\n",
    "        gmax = np.max(cropped_data)\n",
    "        gmean = np.mean(cropped_data)\n",
    "        variance = np.var(cropped_data)\n",
    "        #if (gmax-gmin < threshold):\n",
    "        if (strategy == \"minMax\" and gmax - gmin < threshold) or (strategy == \"variance\" and np.sqrt(variance) < threshold):\n",
    "            newc = create_cube(xyzmin, xyzmax, gmin, gmax, gmean, variance, leaf=True, level=newlevel)\n",
    "        else:\n",
    "            newc = create_cube(xyzmin, xyzmax, gmin, gmax, gmean, variance, leaf=False, level=newlevel)\n",
    "        clist.append(newc)\n",
    "    return clist\n",
    "    \n",
    "\n",
    "\n",
    "# The SPLIT loop...\n",
    "def split3D(data_3Dimg, rootc, min_size, sim_threshold, strategy):\n",
    "    \"\"\"\n",
    "    Split a 3D img in octree according gray level values\n",
    "    Parameters\n",
    "    ----------\n",
    "    data-3Dimg: the 3D volume of the 3D image to split\n",
    "    rootc:  the root cube corresponding to the image size\n",
    "    min_size : minimun size of a cube during the split\n",
    "    sim_threshold: gray level homogeneity threshold to stop splitting\n",
    "    Returns\n",
    "    -------\n",
    "    a graph resulting of the split. Each node is a cube with attributes and each edge is an adjacency between 2 cubes\n",
    "    the segmented volume\n",
    "    \"\"\"\n",
    "    cpt = 0               # used just to print feedbacks regularely\n",
    "\n",
    "    cubestoprocess = []\n",
    "    leafGraph = nx.Graph()\n",
    "    data_img_copy = np.copy(data_3Dimg)\n",
    "\n",
    "    cubestoprocess.append(rootc)\n",
    "\n",
    "    while len(cubestoprocess) > 0 :    \n",
    "        cub = cubestoprocess.pop()    \n",
    "        oct = split(cub, minsize=min_size)\n",
    "        if np.any(oct) :\n",
    "            childlist = octree2cube(cub, oct, data_3Dimg, sim_threshold, strategy)\n",
    "            for elmt in childlist:\n",
    "\n",
    "                if elmt['leaf'] == True :\n",
    "                    #add to graph\n",
    "                    # Add the leaf node in the RAG / before it was done with add_leaf_node(leafGraph,elmt)\n",
    "                    id = leafGraph.number_of_nodes()+1\n",
    "                    leafGraph.add_node(id)\n",
    "                    nx.set_node_attributes(leafGraph, {id:elmt})            \n",
    "\n",
    "                    data_img_copy[ elmt['xyzmin'][0]: elmt['xyzmax'][0], elmt['xyzmin'][1]: elmt['xyzmax'][1], elmt['xyzmin'][2]: elmt['xyzmax'][2]] = int( (elmt['graymax'] + elmt['graymin'])/2 )\n",
    "                    #print(\"- Level = \", elmt['level'],\" Similarity = \", elmt['graymax'] - elmt['graymin'] )\n",
    "                else:\n",
    "                    #add to process\n",
    "                    cubestoprocess.append(elmt)        \n",
    "        else:\n",
    "            #cub is Too small to be splitted so become a leaf  \n",
    "            cub['leaf'] = True\n",
    "            #Add the leaf node in the RAG / before it was done with add_leaf_node(leafGraph,cub)\n",
    "            id = leafGraph.number_of_nodes()+1\n",
    "            leafGraph.add_node(id)\n",
    "            nx.set_node_attributes(leafGraph, {id:cub})            \n",
    "            data_img_copy[ cub['xyzmin'][0]: cub['xyzmax'][0], cub['xyzmin'][1]: cub['xyzmax'][1], cub['xyzmin'][2]: cub['xyzmax'][2]] = int( (cub['graymax'] + cub['graymin'])/2 )\n",
    "            \n",
    "        # Just to provide feedbacks of the progress...\n",
    "        cpt+=1\n",
    "        if cpt > 50 :\n",
    "            print(\"- Queue : \",len(cubestoprocess),\" - Level = \", elmt['level'],\" Similarity = \", elmt['graymax'] - elmt['graymin'] )                                \n",
    "            cpt = 0\n",
    "\n",
    "    print(\"Split done.\")\n",
    "    return leafGraph, data_img_copy\n",
    "    \n",
    "\n",
    "\n",
    "# The MERGE loop....\n",
    "def merge3D(data_3Dimg, g, sim_threshold, strategy):\n",
    "    \"\"\"    \n",
    "    Merge splitted regions resulting of a split in octree occording to a RAG graph and to gray levels inside region \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_3Dimg: the 3D volume of the 3D image to split\n",
    "    g: the graph corresponding to the splitted 3D volume \n",
    "    sim_threshold: gray level homogeneity threshold to stop splitting\n",
    "    Returns\n",
    "    -------\n",
    "    final number of regions\n",
    "    the segmented 3D volume (with region_label on each voxel)\n",
    "    \"\"\"\n",
    "\n",
    "    #data_img_copy = np.copy(data_3Dimg)\n",
    "    data_img_copy = np.zeros_like(data_3Dimg, dtype=np.uint16)\n",
    "\n",
    "    # Give a label to each Region \n",
    "    regionid = 1\n",
    "    for node in g.nodes:                      \n",
    "        # Background should be associated with a specific processing \n",
    "        if g.nodes[node]['graymax'] > 0 :\n",
    "            # Not Background\n",
    "            g.nodes[node]['region_label'] = regionid\n",
    "            regionid+=1\n",
    "        else:\n",
    "            # Is Background\n",
    "            g.nodes[node]['region_label'] = 0\n",
    "\n",
    "        # g.nodes[node]['region_label'] = regionid\n",
    "        # regionid+=1       \n",
    "\n",
    "        # Initialize the label image with each node label\n",
    "        data_img_copy[ g.nodes[node]['xyzmin'][0]: g.nodes[node]['xyzmax'][0], g.nodes[node]['xyzmin'][1]: g.nodes[node]['xyzmax'][1], g.nodes[node]['xyzmin'][2]: g.nodes[node]['xyzmax'][2]] = (g.nodes[node]['region_label'])             \n",
    "        # end of loop on nodes\n",
    "\n",
    "    print(\"Nb of ROI before merge :\",regionid)\n",
    "\n",
    "    #Label propagation between neighbors\n",
    "    sorted_edges = sort_edges_by_attribute(g, 'level')    # Start from big regions\n",
    "    fusion = nofusion = 0\n",
    "\n",
    "    for edge in sorted_edges:        \n",
    "        node1, node2, attributes = edge                       \n",
    "        #there are different possibilities to fill gmin and gmax below... \n",
    "        gmax = attributes['graymax'] # could be max with gmax values of the 2 nodes because these values change along merging \n",
    "        gmin = attributes['graymin'] # could be min with gmin values of the 2 nodes\n",
    "        vol1 = g.nodes[node1]['volume']\n",
    "        vol2 = g.nodes[node2]['volume']\n",
    "        mean1 = g.nodes[node1]['graymean']\n",
    "        mean2 = g.nodes[node2]['graymean']\n",
    "        var1 = g.nodes[node1]['variance']\n",
    "        var2 = g.nodes[node2]['variance']\n",
    "        vol_global = vol1 + vol2\n",
    "        gray_mean_global = (vol1 * mean1 + vol2 * mean2) / vol_global\n",
    "        var_globale = vol1 * (var1 + (gray_mean_global - mean1)**2) + vol2 * (var2 + (gray_mean_global - mean2)**2) / (vol_global)\n",
    "        \n",
    "        # if gmax - gmin < sim_threshold:\n",
    "        # if np.sqrt(var_globale) < sim_threshold:\n",
    "        if (strategy == \"minMax\" and gmax - gmin < sim_threshold) or (strategy == \"variance\" and np.sqrt(var_globale) < sim_threshold):      \n",
    "            # Update label image\n",
    "            data_img_copy[ g.nodes[node1]['xyzmin'][0]: g.nodes[node1]['xyzmax'][0], g.nodes[node1]['xyzmin'][1]: g.nodes[node1]['xyzmax'][1], g.nodes[node1]['xyzmin'][2]: g.nodes[node1]['xyzmax'][2]] = (g.nodes[node1]['region_label']) \n",
    "            data_img_copy[ g.nodes[node2]['xyzmin'][0]: g.nodes[node2]['xyzmax'][0], g.nodes[node2]['xyzmin'][1]: g.nodes[node2]['xyzmax'][1], g.nodes[node2]['xyzmin'][2]: g.nodes[node2]['xyzmax'][2]] = (g.nodes[node1]['region_label']) \n",
    "            \n",
    "            # upDate nodes attributes\n",
    "            g.nodes[node2]['graymax'] = g.nodes[node1]['graymax'] = gmax\n",
    "            g.nodes[node2]['graymin'] = g.nodes[node1]['graymin'] = gmin\n",
    "            g.nodes[node2]['variance'] = g.nodes[node1]['variance'] = var_globale\n",
    "            g.nodes[node2]['graymean'] = g.nodes[node1]['graymean'] = gray_mean_global\n",
    "            g.nodes[node2]['volume'] = g.nodes[node1]['volume'] = vol_global\n",
    "            g.nodes[node2]['region_label'] = g.nodes[node1]['region_label']\n",
    "            fusion+=1                                          \n",
    "        else:\n",
    "            #update only label image\n",
    "            data_img_copy[ g.nodes[node1]['xyzmin'][0]: g.nodes[node1]['xyzmax'][0], g.nodes[node1]['xyzmin'][1]: g.nodes[node1]['xyzmax'][1], g.nodes[node1]['xyzmin'][2]: g.nodes[node1]['xyzmax'][2]] = (g.nodes[node1]['region_label'])\n",
    "            data_img_copy[ g.nodes[node2]['xyzmin'][0]: g.nodes[node2]['xyzmax'][0], g.nodes[node2]['xyzmin'][1]: g.nodes[node2]['xyzmax'][1], g.nodes[node2]['xyzmin'][2]: g.nodes[node2]['xyzmax'][2]] = (g.nodes[node2]['region_label']) \n",
    "            nofusion+=1                               \n",
    "\n",
    "    print(\"Fusion=\",fusion,\" - nofusion=\",nofusion)        \n",
    "    labels = np.unique(data_img_copy)    \n",
    "\n",
    "    return labels, data_img_copy\n",
    "\n",
    "\n",
    "\n",
    "# the split and merge function\n",
    "def split_merge_3D(T_split, T_merge, minimum_size, strategy, data, rootc, nifti_image, output_path=\"\"):\n",
    "    \"\"\"    \n",
    "    Split and Merge a 3D nifti image with gray value intensities corresponding to an octree starting from rootc volume\n",
    "    Parameters\n",
    "    ----------\n",
    "    T: Threshold of similarity of intensities / gray level values\n",
    "    F: minimum lenght of a side for the splitted cubes\n",
    "    data: the 3D volume \n",
    "    rootc: the  cube corresponding to the shape of the image / 3D volume\n",
    "    nifti_image: the corresponding nifti image (needed just to save partial result of the split step in a nifti file)\n",
    "    output_path: the path where to save the partial result (optional)\n",
    "    Returns\n",
    "    -------\n",
    "    array of labels given to the regions\n",
    "    the segmented 3D volume (with region_label on each voxel)\n",
    "    \"\"\"\n",
    "\n",
    "    # Split3D function\n",
    "    print(\"Splitting (+ edges) takes time ...\")\n",
    "    leafGraph, seg_data = split3D(data, rootc, minimum_size, T_split, strategy)\n",
    "    print(\"G size: |V|=\",leafGraph.number_of_nodes(), \"|E|=\",leafGraph.number_of_edges())\n",
    "    \n",
    "    print(\"RAG creation (can takes a lot of time ...)\")\n",
    "    find_cube_adjacencies(leafGraph)\n",
    "    print(\"RAG size: |V|=\",leafGraph.number_of_nodes(), \"|E|=\",leafGraph.number_of_edges())\n",
    "    \n",
    "    # Save split result in a niftii file if provided\n",
    "    # if output_path != \"\":\n",
    "    #     splitted_nifti = nib.Nifti1Image(seg_data, affine=nifti_image.affine, header=nifti_image.header)\n",
    "    #     nib.save(splitted_nifti, output_path)\n",
    "\n",
    "    # Merge3D function\n",
    "    print(\"Merging...\")\n",
    "    llabels, final_data = merge3D(seg_data, leafGraph, T_merge, strategy)\n",
    "    \n",
    "    return llabels, final_data\n",
    "\n",
    "\n",
    "\n",
    "#generate colors\n",
    "def generate_basic_colors(N):\n",
    "    basic_colors = [\n",
    "        (255, 0, 0),      # Red\n",
    "        (0, 255, 0),      # Green\n",
    "        (0, 0, 255),      # Blue\n",
    "        (255, 255, 0),    # Yellow\n",
    "        (255, 0, 255),    # Magenta\n",
    "        (0, 255, 255),    # Cyan\n",
    "        (128, 128, 128),  # Gray\n",
    "        (128, 0, 0),      # Maroon\n",
    "        (0, 128, 0),      # Olive\n",
    "        (0, 0, 128),      # Navy\n",
    "        (128, 128, 0),    # Olive Green\n",
    "        (128, 0, 128),    # Purple\n",
    "        (0, 128, 128),    # Teal\n",
    "        (128, 128, 192),  # Sky Blue\n",
    "        (128, 64, 64),    # Brown\n",
    "        (64, 128, 64),    # Dark Green\n",
    "        (64, 64, 128),    # Indigo\n",
    "        (128, 128, 64),   # Yellow Green\n",
    "        (128, 64, 128),   # Dark Purple\n",
    "        (64, 128, 128)    # Light Teal\n",
    "    ]\n",
    "    \n",
    "    N = (N + 1) % len(basic_colors)\n",
    "    return basic_colors[N]\n",
    "    \n",
    "\n",
    "# Create an ITK label file with random color for the list of found ROIs\n",
    "def create_itk_labels_file(labels, filename, comment=\"\"):\n",
    "    \"\"\"\n",
    "    Create an ITK label file with random color for the list of found ROIs\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels: list of labels\n",
    "    filename: name of the file to create\n",
    "    comment: comment to add at the beginning of the file\n",
    "    Returns\n",
    "    -------\n",
    "    Nothing\n",
    "    \"\"\"\n",
    "    cpt = 0\n",
    "    # Open the log file in append mode\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"### Label file in ITK Snap format for \" + filename + \"\\r\\n\")\n",
    "        f.write(comment + \"\\r\\n\\r\\n\")\n",
    "\n",
    "        # Loop through the labels \n",
    "        for label in labels :\n",
    "            # Write the information              \n",
    "            if label == 0:\n",
    "                r,v,b = (0,0,0)\n",
    "            else:\n",
    "                r,v,b = generate_basic_colors(cpt)                   \n",
    "            tline = \" \" + str(int(label)) + \" \" + str(r) + \" \" + str(v) + \" \" + str(b) + \" \\\"ROI \" + str(int(label)) + \"\\\" \\r\\n\"                                   \n",
    "            f.write(tline)\n",
    "            cpt += 1            \n",
    "    f.close()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "###############################################\n",
    "# Loop to segment all the images inside a directory\n",
    "def split_merge_3D_batch(input_dir, output_dir, T = 20, F = 9):\n",
    "    \"\"\"    \n",
    "    Loop to segment all the images inside a directory\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_dir: directory containing the images to process (nii.gz)\n",
    "    output_dir : directory to put the results (should exist)\n",
    "    # SPLI & MERGE PARAMETERS\n",
    "    T: gray level homogeneity threshold\n",
    "    F: Minimun size during split\n",
    "    Returns\n",
    "    -------\n",
    "    Nothing\n",
    "    \"\"\"\n",
    "     \n",
    "    print(\"Running batch.... \")  \n",
    "    \n",
    "    # Open the log file in append mode\n",
    "    log_file = output_dir + 'C:/Users/cassa/Documents/INFO S4 L2/splitandmerge3D (2)/cailles/c_matrix_AB.txt'\n",
    "\n",
    "    f = open(log_file, 'w')\n",
    "    \n",
    "    # Enumerate NIfTI files in the input directory\n",
    "    nifti_files = [file for file in os.listdir(input_dir) if file.find(\"label\") == -1 and file.endswith('.nii.gz')]\n",
    "\n",
    "    # Loop through each NIfTI file\n",
    "    for nifti_file in nifti_files:\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Construct the file paths\n",
    "        input_path = os.path.join(input_dir, nifti_file)\n",
    "        output_path = os.path.join(output_dir, nifti_file)    \n",
    "        \n",
    "        info = split_merge_3D_1img(input_path,output_path)\n",
    "\n",
    "        # Update log file with processed image info\n",
    "        f.write(f\"Processed image : {output_path}\")  \n",
    "        f.write(info)  \n",
    "        f.write(f\" - processing time = {(time.time() - start_time)}\\n\")            \n",
    "        f.write(\"\\n\")\n",
    "        f.flush()\n",
    "\n",
    "        print(f\"Image {output_path} saved. \\n\\n\")\n",
    "        \n",
    "    print(\"Batch done\")\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################\n",
    "# THE MAIN SPLIT AND MERGE FUNCTION \n",
    "def split_merge_3D_1img(image_path,output_path, T_split, T_merge, minimum_size, strategy):\n",
    "    \"\"\"\n",
    "    The main split and merge 3D function for one image including preprocessing and post processing.\n",
    "    -------\n",
    "    Parameters\n",
    "    -------\n",
    "    image_path:  image to process (nii.gz)\n",
    "    output_path : output path of the resulting segmented image (path of the itk label file decuded from this one)\n",
    "    REM: for the moment the SPLIT & MERGE PARAMETERS have to be set manually in this function\n",
    "    T_split: gray level homogeneity threshold during split\n",
    "    T_merge: gray level homogeneity threshold during merge\n",
    "    minimum_size: used by post processing to remove small region returned by split and merge (actually set to 2xFxFxF)\n",
    "    -------\n",
    "    Returns\n",
    "    -------\n",
    "    String containing info about the result\n",
    "    \"\"\"\n",
    "\n",
    "    output_path_label = output_path  + \".label\"\n",
    "        \n",
    "    # Load NIfTI image\n",
    "    nifti_file = image_path\n",
    "    nifti_image = nib.load(nifti_file)\n",
    "    imgdata = nifti_image.get_fdata()\n",
    "    origin = nib.Nifti1Image(imgdata, affine=nifti_image.affine)\n",
    "    nib.save(origin, 'caille\\\\caille_origin.nii.gz')\n",
    "    gmin = np.min(imgdata)\n",
    "    gmax = np.max(imgdata)\n",
    "    gmean = np.mean(imgdata)\n",
    "    print(\"Initial Image: shape = \",imgdata.shape, \" - (min,max)=\",gmin,gmax)\n",
    "    \n",
    "    # Pre-processing on the image     \n",
    "    print(\"Pre-processing image...\")\n",
    "    data = augment_contrast(imgdata)\n",
    "    data = normalize_data(data)          # mandatory step\n",
    "    data = mg_filter_3d_nifti(data, sigma=0.5, kernel_size = (3,3,3))\n",
    "    # data = mg_filter_3d_nifti(imgdata, sigma=1.5)\n",
    "    prepro = nib.Nifti1Image(data, affine=nifti_image.affine)\n",
    "    nib.save(prepro, 'caille\\\\caille_prepro.nii.gz')\n",
    "\n",
    "\n",
    "    # Corresponding Root Cube creation\n",
    "    rootc = create_cube([0,0,0],data.shape, np.min(data), np.max(data), np.mean(data), np.var(data))\n",
    "    print(\"Initial Cube=\", rootc, \" - data type=\",data.dtype )\n",
    "    print(\"- Split & Merge 3D with T=\",T_split,\" - Minimum size of a cube=\",minimum_size)\n",
    "    rlabels, result_data = split_merge_3D(T_split, T_merge, minimum_size, strategy, data, rootc, nifti_image)\n",
    "    print(\"- Nb of Regions = \", len(rlabels),\" - Labels = \", rlabels , \" - data type = \",result_data.dtype)\n",
    "\n",
    "    # Post-processing to remove some regions ???\n",
    "    minimum_size = 2*minimum_size*minimum_size*minimum_size     #minimum volume = k x (volume of the minimum cube)\n",
    "    # rlabels, result_data = remove_merge_again(rlabels, result_data, minimum_size)\n",
    "\n",
    "    # print(\"- Final nb of Regions (in ITK file) = \", len(rlabels),\" - Labels = \", rlabels, \" - data type = \",result_data.dtype)\n",
    "\n",
    "\n",
    "    # Save the final segmentation result in a niftii file\n",
    "    #final_nifti = nib.Nifti1Image(final_data, affine=nifti_image.affine, header=nifti_image.header)\n",
    "    final_nifti = nib.Nifti1Image(result_data, affine=nifti_image.affine)\n",
    "    print(output_path)\n",
    "    nib.save(final_nifti, output_path)\n",
    "\n",
    "    # Create the labels file for compatibility with 3DBrainMiner\n",
    "    commentaire = \"### Split & Merge 3D with T_split=\" + str(T_split) + \" - T_merge=\" + str(T_merge) + \" - F=\" + str(minimum_size) + \" - min-Size=\"  + str(minimum_size) + \" after 3D medianfilter - Nb of ROI=\" + str(len(rlabels)) + \" (\" + str(len(rlabels)) + \")\"\n",
    "    create_itk_labels_file(rlabels, output_path_label,commentaire)\n",
    "    print(commentaire)\n",
    "\n",
    "    # Save all Region masks into niftii files\n",
    "    #for lbl in llabels :\n",
    "    #    output_p = \"C:\\\\DATA\\\\BD_Images\\\\INRAE\\\\Zenodo\\\\zenodo-dataset\\\\MRI\\\\RESULTS\\\\RESULT_\" + str(lbl) + \"_IMG.nii.gz\"\n",
    "    #    create_mask_niftii(lbl,final_data, output_p,nifti_image)\n",
    "    #print(\"Binary masks Saved\")\n",
    "\n",
    "    return commentaire\n",
    "\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# THE MAIN()\n",
    "\n",
    "\n",
    "### Argument parser ###\n",
    "def build_arg_parser() -> argparse.ArgumentParser:\n",
    "\n",
    "    example_text = '''example: python10.exe splitandmerge3D.py --input-file \"myBrain/MyBrain.nii.gz\" --output-folder \"myBrain/segmentation\" --split-threshold 15 --merge-threshold 41 --min-size 6 '''\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Segment a 3D brain image using the Split & Merge algorithm\",\n",
    "        epilog=example_text,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--input-file\", type=str, help=\"Input imagery path (NiFTI file)\", required=True\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output-folder\", type=str, help=\"Output folder path, the name of the file will be '{folder name}_seg_Tsplit-{split threshold}_Tmerge-{merge threshold}_minSize-{minimum size}.nii.gz'\",\n",
    "        default=\"segmentation\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--merge-threshold\",\n",
    "        type=int,\n",
    "        help=\"threshold for merging regions (default: 40)\",\n",
    "        default=40,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--split-threshold\",\n",
    "        type=int,\n",
    "        help=\"threshold for splitting regions (default: 40)\",\n",
    "        default=40,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--min-size\",\n",
    "        type=int,\n",
    "        help=\"minimum size of a region (default: 10)\",\n",
    "        default=10,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--homogeneity-strategy\",\n",
    "        type=str,\n",
    "        choices=[\"minMax\", \"variance\"],\n",
    "        help=\"choose strategy for calculating the homogeneousity of a region. (default: minMax)\",\n",
    "        default=1,\n",
    "    )\n",
    "    return parser\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    arg_parser = build_arg_parser()\n",
    "    args = arg_parser.parse_args()\n",
    "    output = args.output_folder + f\"/seg_Tsplit-{args.split_threshold}_Tmerge-{args.merge_threshold}_minSize-{args.min_size}_strat-{args.homogeneity_strategy}.nii.gz\"\n",
    "    print(f\"Intput MRI path : {args.input_file}\")\n",
    "    print(f\"Output path : {output}\")\n",
    "    print(f\"Merge threshold : {args.merge_threshold}\")\n",
    "    print(f\"Split threshold : {args.split_threshold}\")\n",
    "    print(f\"Minimum size : {args.min_size}\")\n",
    "    print(f\"Strategy : {args.homogeneity_strategy}\")\n",
    "\n",
    "    split_merge_3D_1img(args.input_file, output, args.split_threshold, args.merge_threshold, args.min_size, args.homogeneity_strategy)\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1901c9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_volume(coordinates):\n",
    "\n",
    "    def __init__(self,indice, coordXmax,coordYmax,coordZmax, coordXmin, coordYmin, coordZmin, volume, idNoeud) -> None:\n",
    "        \n",
    "        self.indice = indice         # indice du noeud\n",
    "        self.coordX = coordXmax      # coordX maximal de la région\n",
    "        self.coordY = coordYmax        \n",
    "        self.coordZ = coordZmax\n",
    "        self.volume = volume\n",
    "        self.coordXmin = coordXmin   # coordY minimal de la région\n",
    "        self.coordYmin= coordYmin\n",
    "        self.coordZmin= coordZmin\n",
    "        \n",
    "        graph={}\n",
    "        L=[i for i in regionid]\n",
    "        liste_noeuds=[random.choice(string.ascii_lowercase) for i in range(len(L))]\n",
    "        for i in range(len(liste_noeuds)):\n",
    "            if i<len(L):\n",
    "                graph[liste_noeuds[i]]=L[i]\n",
    "            else:\n",
    "                print(\"Pas assez de chiffres pour tous les noeuds.\")\n",
    "        print(\"Graphe associant les noeuds aux chiffres :\", graph)2..\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53388f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
